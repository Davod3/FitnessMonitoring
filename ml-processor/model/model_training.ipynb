{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efcb6c9",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:60px;\"><strong>Internet of Things 2023/2024</strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c94d54b",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"><strong>ML Model Training</strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3383bbe",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c9555",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8315e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\migue\\anaconda3\\anaconda\\lib\\site-packages (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd200ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as pl\n",
    "\n",
    "from sklearn.model_selection import cross_validate # for cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "##############################################\n",
    "# Funções para converter e reverter a escala \n",
    "###\n",
    "\n",
    "def scale01(x):\n",
    "    return (x - x.min())/(x.max() - x.min())\n",
    "\n",
    "def unscale01(x, lower, upper):\n",
    "    #return (x * (upper - lower)) + lower\n",
    "    return (x * upper) - ((x - 1.0) * lower)\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867e21f9",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee08365d",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"><strong>Reading Data</strong></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ddd126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120618 x 7\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('trainning.data', delimiter=';')\n",
    "\n",
    "data = np.array(df.values[: , 2:], dtype = float)   # Pandas dtype = object, logo tudo é permitido\n",
    "(N, d) = data.shape\n",
    "\n",
    "print(N, 'x', d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96575ec6",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"><strong>Pre-processing & Scaling</strong></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c767de04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum original value: [ 0.     -5.3505 -3.299  -3.7538 -4.4306 -7.4647 -9.48  ]\n",
      "Maximum original value: [ 1.      5.6033  2.668   1.6403  4.8742  8.498  11.2662]\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1.]\n",
      "[ 0.     -5.3505 -3.299  -3.7538 -4.4306 -7.4647 -9.48  ]\n",
      "[ 1.      5.6033  2.668   1.6403  4.8742  8.498  11.2662]\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Primeiro, agregar de várias fontes e fazer alinhamento entre os dados\n",
    "# Neste caso nada a fazer\n",
    "\n",
    "# Segundo, fazer alguns pre-processamentos: Scaling? missing rows? missing values? outliers?\n",
    "\n",
    "# Scaling\n",
    "\n",
    "# keep to revert numbers back to the original range and scale\n",
    "minv = data.min(0)\n",
    "maxv = data.max(0)\n",
    "\n",
    "print(\"Minimum original value:\", minv)\n",
    "print(\"Maximum original value:\", maxv)\n",
    "\n",
    "for var in range(1, 7):\n",
    "    data[:, var] = scale01(data[:, var])\n",
    "\n",
    "print()\n",
    "print(data.min(0))\n",
    "print(data.max(0))\n",
    "\n",
    "# Reverter para a escala e gama original \n",
    "data2 = data.copy()\n",
    "for var in range(1, 7):\n",
    "    data2[:, var] = unscale01(data[:, var], minv[var], maxv[var])\n",
    "\n",
    "print(data2.min(0))\n",
    "print(data2.max(0))\n",
    "\n",
    "# missing rows não é problema\n",
    "# missing values?\n",
    "print()\n",
    "print(np.isfinite(data[:,0]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2aff43",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"><strong>Separate data for Input/Output</strong></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c7a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos separar entrada e saída dos modelos\n",
    "\n",
    "# Entradas são as carateristicas ou variáveis (features) dos dados que medimos e que podem explicar\n",
    "# as classes da saída\n",
    "\n",
    "inputs = data[:, 1:] # Neste caso todas as linhas desde a segunda coluna até à última\n",
    "\n",
    "# A saída representa as classes que pretendemos prever.\n",
    "# No nosso caso temos duas classes (walk, run - nos dados 0, 1)\n",
    "\n",
    "output = data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3525f418",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"><strong>Separate data for Training</strong></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e98ef097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos os dados com 70% para treinar e 30% para avaliar os modelos\n",
    "\n",
    "inputs_train, inputs_test, output_train, output_test = train_test_split(inputs,\n",
    "                                                                        output,\n",
    "                                                                        test_size = 0.3,\n",
    "                                                                        shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bbb2da",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"><strong>SVM Model</strong></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b72b10d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8793456032719836\n",
      "F1-score: 0.8282319616020143\n",
      "Confusion matrix:\n",
      "[[21294   573]\n",
      " [ 3793 10526]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vamos tentar um modelo com uma SVM\n",
    "\n",
    "SVM = SVC(C = 1.0, kernel = 'linear') # kernel 'rbf'\n",
    "\n",
    "SVM.fit(inputs_train, output_train)\n",
    "\n",
    "# Vejamos a accuracy média nos dados de teste\n",
    "print('Accuracy:', SVM.score(inputs_test, output_test))\n",
    "\n",
    "# Vejamos o score F1\n",
    "output_predicted = SVM.predict(inputs_test)\n",
    "print('F1-score:', f1_score(output_test, output_predicted))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(output_test, output_predicted, labels = [0.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb3f97a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy (mean, std): 0.87121341644573 0.024038946295484677\n",
      "F1-socre (mean, std): 0.8151817654081757 0.037383204163012204\n",
      "\n",
      "F1-score:\n",
      "0.9871325333244119\n",
      "{'C': 100, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# No entanto o split pode ter sido uma questão de sorte\n",
    "# Por isso vamos usar validação cruzada\n",
    "\n",
    "# Por outro lado, a accuracy sozinha pode não avaliar bem o desempenho.\n",
    "# Por exemplo quando os dados não estão bem balanceados.\n",
    "\n",
    "metrics = ['accuracy', 'f1']\n",
    "\n",
    "scores = cross_validate(SVM, inputs, output, cv = 10, scoring = metrics, n_jobs = -1)\n",
    "print()\n",
    "print('Accuracy (mean, std):', scores['test_accuracy'].mean(), scores['test_accuracy'].std())\n",
    "print('F1-socre (mean, std):', scores['test_f1'].mean(), scores['test_f1'].std())\n",
    "\n",
    "# E se quisessemos escolher o parâmetro C e o tipo de kernel?\n",
    " \n",
    "grid = {'C': [1, 100], 'kernel': ('linear', 'rbf')}\n",
    "grid_search = GridSearchCV(SVC(), grid, cv = 10, scoring = 'f1', refit = False, n_jobs = -1)\n",
    "grid_search.fit(inputs, output)\n",
    "\n",
    "print()\n",
    "print('F1-score:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6395da0",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"><strong>K Nearest Neighbors Model</strong></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d738033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9909080860001105\n",
      "F1-score: 0.9884614035703013\n",
      "Confusion matrix:\n",
      "[[21765   102]\n",
      " [  227 14092]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vamos tentar um modelo com K Nearest Neighbors\n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors = 3, weights = 'uniform') # weights = ‘distance’\n",
    "KNN.fit(inputs_train, output_train)\n",
    "\n",
    "# Vejamos a accuracy média nos dados de teste\n",
    "print('Accuracy:', KNN.score(inputs_test, output_test))\n",
    "\n",
    "# Vejamos o score F1\n",
    "output_predicted = KNN.predict(inputs_test)\n",
    "print('F1-score:', f1_score(output_test, output_predicted))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(output_test, output_predicted, labels = [0.0, 1.0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d631e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy (mean, std): 0.9886004551477813 0.005002199480548125\n",
      "F1-score (mean, std): 0.9855885278092946 0.00622217698947913\n",
      "\n",
      "F1-score:\n",
      "0.9877141046884136\n",
      "{'n_neighbors': 6, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "metrics = ['accuracy', 'f1']\n",
    "\n",
    "scores = cross_validate(KNN, inputs, output, cv = 10, scoring = metrics, n_jobs = -1)\n",
    "print()\n",
    "print('Accuracy (mean, std):', scores['test_accuracy'].mean(), scores['test_accuracy'].std())\n",
    "print('F1-score (mean, std):', scores['test_f1'].mean(), scores['test_f1'].std())\n",
    "\n",
    "# E se quisessemos escolher o número de vizinhos e outros parâmetros?\n",
    " \n",
    "grid = {'n_neighbors': range(1, 11), 'weights': ('uniform', 'distance')}\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), grid, cv = 10, scoring = 'f1', refit = False, n_jobs = -1)\n",
    "grid_search.fit(inputs, output)\n",
    "print()\n",
    "print('F1-score:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dea1984",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"><strong>Random Forest Model</strong></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b608d59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9917924059028354\n",
      "F1-score: 0.9896055716935569\n",
      "Confusion matrix:\n",
      "[[21751   116]\n",
      " [  181 14138]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vamos tentar um modelo com Random Forest\n",
    "\n",
    "RF= RandomForestClassifier(n_estimators = 10, criterion = 'gini') # criterion = 'entropy'\n",
    "RF.fit(inputs_train, output_train)\n",
    "\n",
    "# Vejamos a accuracy média nos dados de teste\n",
    "print('Accuracy:', RF.score(inputs_test, output_test))\n",
    "\n",
    "# Vejamos o score F1\n",
    "output_predicted = RF.predict(inputs_test)\n",
    "print('F1-score:', f1_score(output_test, output_predicted))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(output_test, output_predicted, labels = [0.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2728c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy (mean, std): 0.990921857444081 0.006315143985079584\n",
      "F1-score (mean, std): 0.9885877748187983 0.007799434378618039\n",
      "\n",
      "F1-score:\n",
      "0.9894806139674858\n",
      "{'criterion': 'entropy', 'n_estimators': 16}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = ['accuracy', 'f1']\n",
    "\n",
    "# No entanto o split pode ter sido uma questão de sorte\n",
    "# Por isso vamos usar validação cruzada\n",
    "\n",
    "scores = cross_validate(RF, inputs, output, cv = 10, scoring = metrics, n_jobs = -1)\n",
    "print()\n",
    "print('Accuracy (mean, std):', scores['test_accuracy'].mean(), scores['test_accuracy'].std())\n",
    "print('F1-score (mean, std):', scores['test_f1'].mean(), scores['test_f1'].std())\n",
    "\n",
    "# E se quisessemos escolher o número de vizinhos e outros parâmetros?\n",
    " \n",
    "grid = {'n_estimators': range(1, 20), 'criterion': ('gini', 'entropy')}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), grid, cv = 10, scoring = 'f1', refit = False, n_jobs = -1)\n",
    "grid_search.fit(inputs, output)\n",
    "print()\n",
    "print('F1-score:')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d986ab97",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"><strong>Best Model - Random Forest Model</strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4342c0",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:20px;\"><strong>Train without Scaled Data</strong></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe5efffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos separar entrada e saída dos modelos\n",
    "\n",
    "# Entradas são as carateristicas ou variáveis (features) dos dados que medimos e que podem explicar\n",
    "# as classes da saída\n",
    "\n",
    "inputs2 = data2[:, 1:] # Neste caso todas as linhas desde a segunda coluna até à última\n",
    "\n",
    "# A saída representa as classes que pretendemos prever.\n",
    "# No nosso caso temos duas classes (walk, run - nos dados 0, 1)\n",
    "\n",
    "output2 = data2[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "492b1e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos os dados com 70% para treinar e 30% para avaliar os modelos\n",
    "\n",
    "inputs_train2, inputs_test2, output_train2, output_test2 = train_test_split(inputs2,\n",
    "                                                                        output2,\n",
    "                                                                        test_size = 0.3,\n",
    "                                                                        shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee29d074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9930636157630023\n",
      "F1-score: 0.9913343690661143\n",
      "Confusion matrix:\n",
      "[[21578    93]\n",
      " [  158 14357]]\n"
     ]
    }
   ],
   "source": [
    "# O melhor modelo é o Random Forest Model, pois parece ser o modelo com o melhor desempenho\n",
    "# entre os 3 avaliados para o trainning.data.\n",
    "# É importante realçar que todos os modelos têm um desempenho bom com altas pontuações de accuracy e F1-score.\n",
    "# No entanto, o KNN e Random Forest models apresentam pontuações ligeiramente superiores em accuracy e\n",
    "# F1-score em comparação com o SVM.\n",
    "\n",
    "# Vamos treinar o modelo com Random Forest com os melhores parâmetros\n",
    "\n",
    "RF_final= RandomForestClassifier(n_estimators = 16, criterion = 'entropy') # criterion = 'entropy'\n",
    "RF_final.fit(inputs_train2, output_train2)\n",
    "\n",
    "# Vejamos a accuracy média nos dados de teste\n",
    "print('Accuracy:', RF_final.score(inputs_test2, output_test2))\n",
    "\n",
    "# Vejamos o score F1\n",
    "output_predicted2 = RF_final.predict(inputs_test2)\n",
    "print('F1-score:', f1_score(output_test2, output_predicted2))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(output_test2, output_predicted2, labels = [0.0, 1.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59668726",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:20px;\"><strong>Train with Scaled Data</strong></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62ba74f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9921516608633173\n",
      "F1-score: 0.990008443568815\n",
      "Confusion matrix:\n",
      "[[21832    97]\n",
      " [  187 14070]]\n"
     ]
    }
   ],
   "source": [
    "# O melhor modelo é o Random Forest Model, pois parece ser o modelo com o melhor desempenho\n",
    "# entre os 3 avaliados para o trainning.data.\n",
    "# É importante realçar que todos os modelos têm um desempenho bom com altas pontuações de accuracy e F1-score.\n",
    "# No entanto, o KNN e Random Forest models apresentam pontuações ligeiramente superiores em accuracy e\n",
    "# F1-score em comparação com o SVM.\n",
    "\n",
    "# Vamos treinar o modelo com Random Forest com os melhores parâmetros\n",
    "\n",
    "RF_final2= RandomForestClassifier(n_estimators = 16, criterion = 'entropy') # criterion = 'entropy'\n",
    "RF_final2.fit(inputs_train, output_train)\n",
    "\n",
    "# Vejamos a accuracy média nos dados de teste\n",
    "print('Accuracy:', RF_final2.score(inputs_test, output_test))\n",
    "\n",
    "# Vejamos o score F1\n",
    "output_predicted = RF_final2.predict(inputs_test)\n",
    "print('F1-score:', f1_score(output_test, output_predicted))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(output_test, output_predicted, labels = [0.0, 1.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a929bc",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:20px;\"><strong>Predict with the model trained without Scaled Data</strong></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c21c40d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsão para a instância: [0.]\n",
      "Resultado Real: [0.]\n"
     ]
    }
   ],
   "source": [
    "# instance 29th\n",
    "new_instance = [0.2843, -0.9344, -0.0459, -0.3433, -0.1396, -3.1056]\n",
    "\n",
    "new_instance = [new_instance]\n",
    "\n",
    "predict = RF_final.predict(new_instance)\n",
    "\n",
    "print(\"Previsão para a instância:\", predict)\n",
    "print(\"Resultado Real: [0.]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75dbc00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance 29th\n",
    "#new_instance = [0.2843, -0.9344, -0.0459, -0.3433, -0.1396, -3.1056]\n",
    "\n",
    "#new_instance_scaled = []\n",
    "\n",
    "#for i in range(len(new_instance)):\n",
    "#    scaled_value = scale01(np.array([new_instance[i]]))\n",
    "#    new_instance_scaled.append(scaled_value[0])\n",
    "    \n",
    "#new_instance_scaled = [new_instance_scaled]\n",
    "\n",
    "#predict_scaled = RF_final2.predict(new_instance_scaled)\n",
    "\n",
    "#print(\"Previsão para a instância:\", predict_scaled)\n",
    "#print(\"Resultado Real: [0.]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d2df71",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"><strong>Saving the model</strong></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b2ebab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_model.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(RF_final, 'trained_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
